{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pd.options.display.mpl_style = 'default'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the dataset and store in the variable 'df'\n",
    "df = pd.read_csv('/Users/colby.schrauth/Desktop/DataScience/query_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List the columns and store them in the variable 'cols'\n",
    "cols = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Push the 'enabled' column to the front of the dataframe\n",
    "cols.insert(0, cols.pop(cols.index('enabled')))\n",
    "\n",
    "#Reorder the dataframe w/ the newly ordered list\n",
    "df = df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Repeat\n",
    "cols.insert(4, cols.pop(cols.index('#_lang')))\n",
    "df = df.ix[:, cols]\n",
    "\n",
    "#Repeat\n",
    "cols.insert(5, cols.pop(cols.index('#_features')))\n",
    "df = df.ix[:, cols]\n",
    "\n",
    "#Repeat\n",
    "cols.insert(6, cols.pop(cols.index('case_count')))\n",
    "df = df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Replace NaN values in 'acct_geo' w/ 'NA'\n",
    "#df[\"acct_geo\"].replace(np.nan,'NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the get_dummies function on the 'acct_geo' column\n",
    "#dummy_update = pd.get_dummies(df[\"acct_geo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produce dummy variables for 'acct_geo' and append them to the original dataframe\n",
    "df = pd.concat([df, pd.get_dummies(df['acct_geo'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Delete the original 'acct_geo' column from the dataframe\n",
    "del df['acct_geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print the shape (rows, columns) of 'df'\n",
    "#print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "df_norm = scaler.fit_transform(df.iloc[:,3:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert df_norm back to a dataframe\n",
    "df_norm = pd.DataFrame(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Append the scaled columns back to the original dataframe\n",
    "df = pd.concat((df, df_norm),1)\n",
    "\n",
    "#Keep 'df_norm' as the dataframe to push through the algorithm\n",
    "df_norm = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the normalized columns in the original dataframe\n",
    "df = df.drop([0, 1, 2, 3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the non-normalized columns in the new dataframe\n",
    "df_norm = df_norm.drop(['comm_age', '#_lang', '#_features', 'case_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the normalized columns in the new dataframe back to their proper title\n",
    "df_norm = df_norm.rename(columns = {\n",
    "    0:'comm_age',\n",
    "    1:'#_lang',\n",
    "    2:'#_features',\n",
    "    3:'case_count',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Slice the categorical/text based columns from the dataframe to prepare for clustering\n",
    "df_norm = df_norm.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the dataframe\n",
    "#df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup a range to iterate through for the sake of plotting the Silhouette Score\n",
    "cluster_range = range(2,21)\n",
    "\n",
    "#Instantiate an empty list to store the results\n",
    "score_list = []\n",
    "\n",
    "#Run a loop through each value for n_clusters\n",
    "for i in cluster_range:\n",
    "    #Instantiate KMeans and fit the data to the curated dataframe\n",
    "    kmeans = KMeans(n_clusters = i, random_state = 1).fit(df_norm)\n",
    "    #Push KMeans labels to the variable 'labels'\n",
    "    labels = kmeans.labels_\n",
    "    #Append each score back to the empty list\n",
    "    score_list.append(silhouette_score(df_norm,labels,metric='euclidean'))\n",
    "\n",
    "#Plot each score vs. n_clusters\n",
    "plt.plot(cluster_range, score_list)\n",
    "plt.xlabel('# of Clusters')\n",
    "plt.ylabel('Silhouette Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find the local maxima to identify the correct # of clusters\n",
    "cluster_count = 2 + max(enumerate(score_list),key=lambda x: x[1])[0]\n",
    "\n",
    "#Display the number of clusters to be used in the model moving forward\n",
    "#cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate KMeans and cluster the dataset around n (n = 'cluster_count') centroids\n",
    "kmeans = KMeans(n_clusters = cluster_count, random_state = 1).fit(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Store labels in the variable 'labels'\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Store cluster center locations in the variable 'centroids'\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add labels as a column to the dataframe\n",
    "df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display the silhouette score for n clusters\n",
    "silhouette_score(df_norm,labels,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display the distribution of accounts by centroid, and whether or not they're enabled\n",
    "#print (pd.crosstab(labels, df[\"enabled\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create column names for the KMeans summary dataframe\n",
    "summary_columns = ['cluster', 'cluster_total', 'cluster_%', 'enabled_#', 'disabled_#', 'enabled_%', 'disabled_%']\n",
    "#headers = list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create an empty list to store summary values\n",
    "summary_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate values for creating a tabular view of the KMeans summary\n",
    "for i in range(cluster_count):\n",
    "    total_in_cluster = float(len(df[df['labels'] == i]))\n",
    "    enabled_count = len(df[(df['labels']==i) & (df['enabled']==1)])\n",
    "    disabled_count = total_in_cluster - enabled_count\n",
    "    d = [i, total_in_cluster, \"%.4f\" %(total_in_cluster / len(df)), enabled_count, disabled_count,\n",
    "         \"%.4f\" %(enabled_count/total_in_cluster),\n",
    "         \"%.4f\" %(disabled_count/total_in_cluster)]\n",
    "    summary_values.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Push summary values to their associated column names and create a dataframe\n",
    "summary_df = pd.DataFrame(summary_values, columns=summary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display the summary table, sorted by disabled in descending order\n",
    "summary_df.sort_values(['cluster_total'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate PCA, and force it to create 2 columns\n",
    "pca_2 = PCA(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Turn the normalized dataframe into two columns with PCA\n",
    "plot_columns = pca_2.fit_transform(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot customers based on the two dimensions, and shade by cluster label\n",
    "plt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=kmeans.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export the updated dataframe to a csv\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Raw data for plot\n",
    "plot_df = pd.DataFrame(plot_columns)\n",
    "plot_df.to_csv('rawplotdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Visualize the KMeans clustering alogrithm\n",
    "for i in range(cluster_count):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = plot_columns[np.where(kmeans.labels_==i)]\n",
    "    # plot the data observations\n",
    "    plt.plot(ds[:,0],ds[:,1],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(centroids[i,0],centroids[i,1],'xk')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=15.0)\n",
    "    plt.setp(lines,mew=2.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Export the updated dataframe to a csv\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#industries (4)\n",
    "#don't normalize binary data\n",
    "#silhoutte score - local maxima (little bump)\n",
    "#number of columns\n",
    "#logistic regression to see if they churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df[list(df.columns[3:5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_norm = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5)\n",
    "km.fit(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids = km.cluster_centers_\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = km.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = data.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "for i in range(k):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = data_norm[np.where(labels==i)]\n",
    "    # plot the data observations\n",
    "    plt.plot(ds[:,0],ds[:,1],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(centroids[i,0],centroids[i,1],'kx')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=15.0)\n",
    "    plt.setp(lines,mew=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "centroids,labels,inertia = cluster.k_means(numpyMatrix,n_clusters=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('colby_test.txt', labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_data = pd.read_csv('http://gadatascience.com/datasets/network_attacks/kddcup.data_10_percent', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdd_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdd_data.protocol_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Turn categorical features into 1-hot encoded features\n",
    "categorical_features = kdd_data[['protocol_type', 'service', 'flag']]\n",
    "dv = DictVectorizer()\n",
    "cat_matrix = dv.fit_transform(categorical_features.T.to_dict().values())\n",
    "\n",
    "# Collect the other numerical features\n",
    "from scipy.sparse import hstack\n",
    "other_features = kdd_data[['src_bytes', 'dst_bytes', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds']]\n",
    "data_matrix = hstack([cat_matrix, other_features])\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "data_matrix = scale(data_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clustering_model = KMeans(n_clusters = 25)\n",
    "clustering_model.fit(data_matrix)\n",
    "\n",
    "clusters = clustering_model.predict(data_matrix)\n",
    "\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({ 'cluster' : clusters, 'class' : kdd_data['class']})\n",
    "cluster_counts = results.groupby('cluster')['class'].value_counts()\n",
    "for i in xrange(len(cluster_counts)):\n",
    "    print(\"Cluster \" ,i)\n",
    "    print(cluster_counts[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change of pace ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# READ IN DATASET\n",
    "votes = pd.read_csv('/Users/colby.schrauth/Desktop/DataScience/114_congress.csv')\n",
    "votes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PRINT THE DATASET SHAPE\n",
    "print votes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PRINT THE UNIQUE VALUES AND THEIR ASSOCIATED FREQUENCY\n",
    "print (pd.value_counts(votes.iloc[:,3:].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT KMEANS\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE A KMEANS MODEL W/ 2 CENTROIDS -- RANDOM_STATE HELPS ENSURE THE ALGORITHM RETURNS THE SAME RESULTS EACH TIME\n",
    "kmeans_model = KMeans(n_clusters = 2, random_state = 1).fit(votes.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# THESE ARE OUR FITTED LABELS FOR CLUSTERS -- THE FIRST CLUSTER HAS LABEL 0, AND THE SECOND HAS LABEL 1\n",
    "labels = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SEPARATE EVERYONE INTO PARTIES BASED ON VOTING HISTORY\n",
    "print (pd.crosstab(labels, votes[\"party\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**APPENDIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshape for clustering with one feature input\n",
    "df_norm = np.reshape(df_norm, (len(df), 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
